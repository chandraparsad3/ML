{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ8zARBj8iZ7"
      },
      "source": [
        "# Download Dataset from Here\n",
        "https://drive.google.com/file/d/1jlI2H9nXrJlrIcoL8PShjdwIV--UNM15/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BSCwyoKU3Sq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3P1fthvCGZx",
        "outputId": "aa8ef11f-8bf5-49f8-cd72-bb9c1c37a8ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, kt-legacy, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, keras_tuner, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 keras_tuner-1.4.7 kt-legacy-1.0.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.5 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio tensorflow keras keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfwkFlVscdU9",
        "outputId": "b92bd687-3ed8-4bac-87d5-8a1bf0cf07ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.51)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
            "  Downloading langchain_core-0.3.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.72.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.52-py3-none-any.whl (433 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.51\n",
            "    Uninstalling langchain-core-0.3.51:\n",
            "      Successfully uninstalled langchain-core-0.3.51\n",
            "Successfully installed langchain-core-0.3.52 langchain-openai-0.3.13 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SsTNusaGxMme",
        "outputId": "7e32c814-7d03-4011-8b5f-c80ba9353f57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0893b126bd1f03f9b4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0893b126bd1f03f9b4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7571 - loss: 0.7005 - val_accuracy: 0.7593 - val_loss: 0.5622\n",
            "Epoch 2/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7593 - loss: 0.5608 - val_accuracy: 0.7593 - val_loss: 0.5520\n",
            "Epoch 3/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7565 - loss: 0.5617 - val_accuracy: 0.7593 - val_loss: 0.5549\n",
            "Epoch 4/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7587 - loss: 0.5573 - val_accuracy: 0.7593 - val_loss: 0.5538\n",
            "Epoch 5/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7602 - loss: 0.5543 - val_accuracy: 0.7593 - val_loss: 0.5530\n",
            "Epoch 6/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7577 - loss: 0.5561 - val_accuracy: 0.7593 - val_loss: 0.5526\n",
            "Epoch 7/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7579 - loss: 0.5552 - val_accuracy: 0.7593 - val_loss: 0.5523\n",
            "Epoch 8/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7583 - loss: 0.5549 - val_accuracy: 0.7593 - val_loss: 0.5521\n",
            "Epoch 9/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7562 - loss: 0.5568 - val_accuracy: 0.7593 - val_loss: 0.5520\n",
            "Epoch 10/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7565 - loss: 0.5552 - val_accuracy: 0.7593 - val_loss: 0.5518\n",
            "Epoch 11/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7576 - loss: 0.5547 - val_accuracy: 0.7593 - val_loss: 0.5522\n",
            "Epoch 12/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7591 - loss: 0.5535 - val_accuracy: 0.7593 - val_loss: 0.5515\n",
            "Epoch 13/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7569 - loss: 0.5550 - val_accuracy: 0.7593 - val_loss: 0.5513\n",
            "Epoch 14/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7616 - loss: 0.5496 - val_accuracy: 0.7593 - val_loss: 0.5513\n",
            "Epoch 15/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7578 - loss: 0.5536 - val_accuracy: 0.7593 - val_loss: 0.5519\n",
            "Epoch 16/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7608 - loss: 0.5503 - val_accuracy: 0.7593 - val_loss: 0.5515\n",
            "Epoch 17/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7569 - loss: 0.5546 - val_accuracy: 0.7593 - val_loss: 0.5510\n",
            "Epoch 18/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7626 - loss: 0.5480 - val_accuracy: 0.7593 - val_loss: 0.5509\n",
            "Epoch 19/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7581 - loss: 0.5527 - val_accuracy: 0.7593 - val_loss: 0.5515\n",
            "Epoch 20/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7646 - loss: 0.5461 - val_accuracy: 0.7593 - val_loss: 0.5509\n",
            "Epoch 21/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7580 - loss: 0.5532 - val_accuracy: 0.7593 - val_loss: 0.5510\n",
            "Epoch 22/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7588 - loss: 0.5521 - val_accuracy: 0.7593 - val_loss: 0.5507\n",
            "Epoch 23/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7625 - loss: 0.5484 - val_accuracy: 0.7593 - val_loss: 0.5506\n",
            "Epoch 24/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7612 - loss: 0.5490 - val_accuracy: 0.7593 - val_loss: 0.5505\n",
            "Epoch 25/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7609 - loss: 0.5497 - val_accuracy: 0.7593 - val_loss: 0.5505\n",
            "Epoch 26/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7589 - loss: 0.5516 - val_accuracy: 0.7593 - val_loss: 0.5506\n",
            "Epoch 27/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7592 - loss: 0.5514 - val_accuracy: 0.7593 - val_loss: 0.5508\n",
            "Epoch 28/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7624 - loss: 0.5476 - val_accuracy: 0.7593 - val_loss: 0.5517\n",
            "Epoch 29/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7595 - loss: 0.5513 - val_accuracy: 0.7593 - val_loss: 0.5504\n",
            "Epoch 30/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7566 - loss: 0.5541 - val_accuracy: 0.7593 - val_loss: 0.5504\n",
            "Epoch 31/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7577 - loss: 0.5532 - val_accuracy: 0.7593 - val_loss: 0.5504\n",
            "Epoch 32/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7634 - loss: 0.5462 - val_accuracy: 0.7593 - val_loss: 0.5504\n",
            "Epoch 33/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7622 - loss: 0.5477 - val_accuracy: 0.7593 - val_loss: 0.5505\n",
            "Epoch 34/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7604 - loss: 0.5504 - val_accuracy: 0.7593 - val_loss: 0.5505\n",
            "Epoch 35/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7622 - loss: 0.5479 - val_accuracy: 0.7593 - val_loss: 0.5502\n",
            "Epoch 36/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7614 - loss: 0.5482 - val_accuracy: 0.7593 - val_loss: 0.5501\n",
            "Epoch 37/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7563 - loss: 0.5547 - val_accuracy: 0.7593 - val_loss: 0.5502\n",
            "Epoch 38/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7580 - loss: 0.5526 - val_accuracy: 0.7593 - val_loss: 0.5503\n",
            "Epoch 39/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7661 - loss: 0.5431 - val_accuracy: 0.7593 - val_loss: 0.5505\n",
            "Epoch 40/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7594 - loss: 0.5507 - val_accuracy: 0.7593 - val_loss: 0.5500\n",
            "Epoch 41/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7549 - loss: 0.5565 - val_accuracy: 0.7593 - val_loss: 0.5499\n",
            "Epoch 42/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7614 - loss: 0.5488 - val_accuracy: 0.7593 - val_loss: 0.5504\n",
            "Epoch 43/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7569 - loss: 0.5544 - val_accuracy: 0.7593 - val_loss: 0.5499\n",
            "Epoch 44/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7629 - loss: 0.5467 - val_accuracy: 0.7593 - val_loss: 0.5497\n",
            "Epoch 45/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7579 - loss: 0.5523 - val_accuracy: 0.7593 - val_loss: 0.5498\n",
            "Epoch 46/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7622 - loss: 0.5481 - val_accuracy: 0.7593 - val_loss: 0.5504\n",
            "Epoch 47/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7601 - loss: 0.5496 - val_accuracy: 0.7593 - val_loss: 0.5497\n",
            "Epoch 48/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7610 - loss: 0.5492 - val_accuracy: 0.7593 - val_loss: 0.5505\n",
            "Epoch 49/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7572 - loss: 0.5533 - val_accuracy: 0.7593 - val_loss: 0.5496\n",
            "Epoch 50/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7571 - loss: 0.5533 - val_accuracy: 0.7593 - val_loss: 0.5494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7478 - loss: 0.7096 - val_accuracy: 0.7593 - val_loss: 0.5621\n",
            "Epoch 2/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7576 - loss: 0.5645 - val_accuracy: 0.7593 - val_loss: 0.5357\n",
            "Epoch 3/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7594 - loss: 0.5469 - val_accuracy: 0.7593 - val_loss: 0.5527\n",
            "Epoch 4/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7585 - loss: 0.5586 - val_accuracy: 0.7593 - val_loss: 0.5548\n",
            "Epoch 5/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7577 - loss: 0.5578 - val_accuracy: 0.7593 - val_loss: 0.5532\n",
            "Epoch 6/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7591 - loss: 0.5544 - val_accuracy: 0.7593 - val_loss: 0.5523\n",
            "Epoch 7/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7597 - loss: 0.5534 - val_accuracy: 0.7593 - val_loss: 0.5518\n",
            "Epoch 8/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7591 - loss: 0.5536 - val_accuracy: 0.7593 - val_loss: 0.5512\n",
            "Epoch 9/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7602 - loss: 0.5514 - val_accuracy: 0.7593 - val_loss: 0.5511\n",
            "Epoch 10/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7633 - loss: 0.5481 - val_accuracy: 0.7593 - val_loss: 0.5516\n",
            "Epoch 11/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7613 - loss: 0.5502 - val_accuracy: 0.7593 - val_loss: 0.5513\n",
            "Epoch 12/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7575 - loss: 0.5544 - val_accuracy: 0.7593 - val_loss: 0.5509\n",
            "Epoch 13/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7620 - loss: 0.5490 - val_accuracy: 0.7593 - val_loss: 0.5507\n",
            "Epoch 14/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7608 - loss: 0.5493 - val_accuracy: 0.7593 - val_loss: 0.5507\n",
            "Epoch 15/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7601 - loss: 0.5509 - val_accuracy: 0.7593 - val_loss: 0.5499\n",
            "Epoch 16/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7573 - loss: 0.5530 - val_accuracy: 0.7593 - val_loss: 0.5501\n",
            "Epoch 17/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7628 - loss: 0.5475 - val_accuracy: 0.7593 - val_loss: 0.5505\n",
            "Epoch 18/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7626 - loss: 0.5474 - val_accuracy: 0.7593 - val_loss: 0.5531\n",
            "Epoch 19/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.5500 - val_accuracy: 0.7593 - val_loss: 0.5493\n",
            "Epoch 20/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.5494 - val_accuracy: 0.7593 - val_loss: 0.5491\n",
            "Epoch 21/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7589 - loss: 0.5515 - val_accuracy: 0.7593 - val_loss: 0.5492\n",
            "Epoch 22/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7599 - loss: 0.5497 - val_accuracy: 0.7593 - val_loss: 0.5504\n",
            "Epoch 23/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7545 - loss: 0.5561 - val_accuracy: 0.7593 - val_loss: 0.5499\n",
            "Epoch 24/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7573 - loss: 0.5524 - val_accuracy: 0.7593 - val_loss: 0.5492\n",
            "Epoch 25/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7546 - loss: 0.5561 - val_accuracy: 0.7593 - val_loss: 0.5492\n",
            "Epoch 26/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7586 - loss: 0.5510 - val_accuracy: 0.7593 - val_loss: 0.5484\n",
            "Epoch 27/50\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7616 - loss: 0.5471 - val_accuracy: 0.7593 - val_loss: 0.5497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2  # Added for L2 regularization\n",
        "import keras_tuner as kt\n",
        "import io\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Global variables to store the trained model and its type\n",
        "trained_model = None\n",
        "trained_model_type = None\n",
        "feature_columns = None\n",
        "x_train, x_test, y_train, y_test = None, None, None, None  # Initialize globally\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_data():\n",
        "    df = pd.read_csv(\"/content/adult.data\")\n",
        "    df.replace(\"?\", pd.NA, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df = pd.get_dummies(df, columns=[\"workclass\", \"education\", \"marital-status\", \"occupation\",\n",
        "                                    \"relationship\", \"race\", \"sex\", \"native-country\", \"income\"],\n",
        "                        drop_first=True)\n",
        "    df.columns = df.columns.str.strip().str.replace(\" \", \"_\")\n",
        "    df = df.astype(int)\n",
        "\n",
        "    X = df.drop(columns=['income__>50K'])\n",
        "    y = df['income__>50K']\n",
        "    split_data = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    return split_data[0], split_data[1], split_data[2], split_data[3], X.columns\n",
        "\n",
        "x_train, x_test, y_train, y_test, feature_columns = load_data()\n",
        "\n",
        "# Function to create LSTM model with hyperparameter tuning and L2 regularization\n",
        "def create_lstm_model(hp=None, input_shape=None):\n",
        "    model = Sequential()\n",
        "    if hp:\n",
        "        lstm1_units = hp.Int('lstm1_units', min_value=32, max_value=128, step=32)\n",
        "        lstm2_units = hp.Int('lstm2_units', min_value=16, max_value=64, step=16)\n",
        "        dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
        "        learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "        l2_lambda = hp.Choice('l2_lambda', values=[0.01, 0.001, 0.0001])  # L2 regularization strength\n",
        "    else:\n",
        "        lstm1_units, lstm2_units, dropout_rate, learning_rate = 64, 32, 0.2, 1e-3\n",
        "        l2_lambda = 0.01  # Default L2 regularization strength\n",
        "\n",
        "    model.add(LSTM(lstm1_units, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(lstm2_units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(16, activation='relu', kernel_regularizer=l2(l2_lambda)))  # L2 regularization\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(l2_lambda)))  # L2 regularization\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Function for XGBoost training with RandomizedSearchCV\n",
        "def train_xgboost(tune_hyperparams, x_train, x_test, y_train, y_test):\n",
        "    eval_set = [(x_train, y_train), (x_test, y_test)]\n",
        "    xgb = XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42)\n",
        "\n",
        "    if tune_hyperparams:\n",
        "        param_dist = {\n",
        "            'n_estimators': [110],\n",
        "            'max_depth': [3, 4, 5],\n",
        "            'learning_rate': [0.1, 0.12, 0.14],\n",
        "            'subsample': [0.7, 0.8, 0.9],\n",
        "            'colsample_bytree': [0.6, 0.7, 0.8],\n",
        "            'alpha': [0, 0.1, 1.0],  # L1 regularization\n",
        "            'lambda': [0.1, 1.0, 10.0]  # L2 regularization\n",
        "        }\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=xgb,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            cv=3,\n",
        "            scoring='accuracy',\n",
        "            n_jobs=-1,\n",
        "            verbose=1,\n",
        "            random_state=42\n",
        "        )\n",
        "        random_search.fit(x_train, y_train)\n",
        "        model = random_search.best_estimator_\n",
        "        best_params = random_search.best_params_\n",
        "    else:\n",
        "        model = xgb\n",
        "        best_params = \"Default parameters\"\n",
        "\n",
        "    model.fit(x_train, y_train, eval_set=eval_set, verbose=False)\n",
        "    results = model.evals_result()\n",
        "    y_pred = model.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return model, results, y_pred, accuracy, best_params\n",
        "\n",
        "# Function to preprocess user input and predict\n",
        "def predict_user_input(model_choice, *user_inputs):\n",
        "    global trained_model, trained_model_type, feature_columns, x_train\n",
        "\n",
        "    if trained_model is None or trained_model_type != model_choice:\n",
        "        return \"Please train the model first by clicking 'Train Model' with the selected model type.\"\n",
        "\n",
        "    try:\n",
        "        user_data = pd.DataFrame([user_inputs], columns=['age', 'fnlwgt', 'education_num', 'capital_gain',\n",
        "                                                         'capital_loss', 'hours_per_week', 'workclass',\n",
        "                                                         'education', 'marital_status', 'occupation',\n",
        "                                                         'relationship', 'race', 'sex', 'native_country'])\n",
        "\n",
        "        user_data_encoded = pd.get_dummies(user_data, columns=['workclass', 'education', 'marital_status',\n",
        "                                                              'occupation', 'relationship', 'race', 'sex',\n",
        "                                                              'native_country'], drop_first=True)\n",
        "        user_data_encoded.columns = user_data_encoded.columns.str.strip().str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
        "\n",
        "        missing_cols = set(feature_columns) - set(user_data_encoded.columns)\n",
        "        for col in missing_cols:\n",
        "            user_data_encoded[col] = 0\n",
        "        user_data_encoded = user_data_encoded[feature_columns]\n",
        "\n",
        "        if model_choice == \"XGBoost\":\n",
        "            prediction = trained_model.predict(user_data_encoded)[0]\n",
        "        else:  # LSTM\n",
        "            user_data_lstm = np.reshape(user_data_encoded.values, (1, 1, user_data_encoded.shape[1]))\n",
        "            if user_data_lstm.shape[2] != x_train.shape[1]:\n",
        "                return f\"Error: Input feature count ({user_data_lstm.shape[2]}) doesn’t match model’s expected count ({x_train.shape[1]})\"\n",
        "            raw_pred = trained_model.predict(user_data_lstm, verbose=0)\n",
        "            prediction = (raw_pred > 0.5).astype(int)[0][0]\n",
        "\n",
        "        result = \">50K\" if prediction == 1 else \"<=50K\"\n",
        "        return f\"Prediction for your input: {result}\\nModel used: {model_choice}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error during prediction: {str(e)}\"\n",
        "\n",
        "# Training function with LSTM tuning\n",
        "def train_model(model_choice, tune_hyperparams):\n",
        "    global trained_model, trained_model_type, x_train, x_test, y_train, y_test\n",
        "\n",
        "    if x_train is None or x_test is None or y_train is None or y_test is None:\n",
        "        return \"Error: Training data not loaded. Please ensure 'adult.data' is available and reload the script.\", None\n",
        "\n",
        "    X_train_lstm = np.reshape(x_train.values, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "    X_test_lstm = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "\n",
        "    if model_choice == \"XGBoost\":\n",
        "        model, results, y_pred, accuracy, best_params = train_xgboost(\n",
        "            tune_hyperparams, x_train, x_test, y_train, y_test\n",
        "        )\n",
        "    else:  # LSTM\n",
        "        if tune_hyperparams:\n",
        "            tuner = kt.RandomSearch(\n",
        "                lambda hp: create_lstm_model(hp, (1, x_train.shape[1])),  # Adjusted input_shape to (1, ...)\n",
        "                objective='val_accuracy',\n",
        "                max_trials=5,\n",
        "                executions_per_trial=2,\n",
        "                directory='lstm_tuning',\n",
        "                project_name='income_prediction'\n",
        "            )\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=14, restore_best_weights=True, mode='min')\n",
        "            tuner.search(X_train_lstm, y_train, epochs=30, batch_size=64,\n",
        "                         validation_data=(X_test_lstm, y_test), callbacks=[early_stopping], verbose=0)\n",
        "            model = tuner.get_best_models(num_models=1)[0]\n",
        "            best_hps = tuner.get_best_hyperparameters(num_trials=1)[0].values\n",
        "            best_params = {k: v for k, v in best_hps.items()}\n",
        "            history = model.fit(X_train_lstm, y_train, epochs=40, batch_size=64,\n",
        "                               validation_data=(X_test_lstm, y_test), callbacks=[early_stopping], verbose=1)\n",
        "        else:\n",
        "            model = create_lstm_model(input_shape=(1, x_train.shape[1]))  # Adjusted input_shape to (1, ...)\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True, mode='min')\n",
        "            history = model.fit(X_train_lstm, y_train, epochs=50, batch_size=64,\n",
        "                               validation_data=(X_test_lstm, y_test), callbacks=[early_stopping], verbose=1)\n",
        "            best_params = \"LSTM default parameters\"\n",
        "\n",
        "        results = {\n",
        "            'validation_0': {'logloss': history.history['loss'], 'acc': history.history['accuracy']},\n",
        "            'validation_1': {'logloss': history.history['val_loss'], 'acc': history.history['val_accuracy']}\n",
        "        }\n",
        "        y_pred = (model.predict(X_test_lstm, verbose=0) > 0.5).astype(int).flatten()\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if model_choice == \"XGBoost\":\n",
        "        model.save_model('model.xgb')\n",
        "    else:\n",
        "        model.save('model_lstm.keras')\n",
        "    trained_model = model\n",
        "    trained_model_type = model_choice\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    ax1.plot(results['validation_0']['logloss'], label='Train Loss')\n",
        "    ax1.plot(results['validation_1']['logloss'], label='Test Loss')\n",
        "    ax1.set_title('Loss')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Log Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid()\n",
        "\n",
        "    if model_choice == \"XGBoost\":\n",
        "        train_pred = model.predict(x_train)\n",
        "        test_pred = model.predict(x_test)\n",
        "        train_acc = [accuracy_score(y_train, train_pred)] * len(results['validation_0']['logloss'])\n",
        "        test_acc = [accuracy_score(y_test, test_pred)] * len(results['validation_1']['logloss'])\n",
        "    else:\n",
        "        train_acc = results['validation_0']['acc']\n",
        "        test_acc = results['validation_1']['acc']\n",
        "\n",
        "    ax2.plot(train_acc, label='Train Acc')\n",
        "    ax2.plot(test_acc, label='Test Acc')\n",
        "    ax2.set_title('Accuracy')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.grid()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    buf.seek(0)\n",
        "    img = Image.open(buf)\n",
        "    plt.savefig('training_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "    report = classification_report(y_test, y_pred, target_names=['<=50K', '>50K'])\n",
        "    result_text = (f\"Model trained successfully!\\n\"\n",
        "                   f\"Accuracy: {accuracy:.4f}\\n\"\n",
        "                   f\"Best parameters: {best_params}\\n\\n\"\n",
        "                   f\"Classification Report:\\n{report}\")\n",
        "    return result_text, img\n",
        "\n",
        "# Command-line training function\n",
        "def train_from_terminal(model_choice, tune_hyperparams):\n",
        "    result_text, _ = train_model(model_choice, tune_hyperparams)\n",
        "    print(result_text)\n",
        "    print(\"Training plots saved as 'training_plot.png'\")\n",
        "\n",
        "# Gradio interface\n",
        "def create_gradio_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Income Prediction Model\")\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                model_dropdown = gr.Dropdown(choices=[\"XGBoost\", \"LSTM\"], label=\"Select Model\")\n",
        "                tune_checkbox = gr.Checkbox(label=\"Tune Hyperparameters\")\n",
        "\n",
        "                gr.Markdown(\"### Enter Your Information\")\n",
        "                age = gr.Number(label=\"Age\", value=30)\n",
        "                fnlwgt = gr.Number(label=\"Final Weight (fnlwgt)\", value=77516)\n",
        "                education_num = gr.Number(label=\"Education Number\", value=13)\n",
        "                capital_gain = gr.Number(label=\"Capital Gain\", value=0)\n",
        "                capital_loss = gr.Number(label=\"Capital Loss\", value=0)\n",
        "                hours_per_week = gr.Number(label=\"Hours per Week\", value=40)\n",
        "                workclass = gr.Dropdown(choices=[\"Private\", \"Self-emp-not-inc\", \"Self-emp-inc\", \"Federal-gov\",\n",
        "                                                \"Local-gov\", \"State-gov\", \"Without-pay\", \"Never-worked\"],\n",
        "                                       label=\"Workclass\", value=\"Private\")\n",
        "                education = gr.Dropdown(choices=[\"Bachelors\", \"Some-college\", \"11th\", \"HS-grad\", \"Prof-school\",\n",
        "                                                \"Assoc-acdm\", \"Assoc-voc\", \"9th\", \"7th-8th\", \"12th\", \"Masters\",\n",
        "                                                \"1st-4th\", \"10th\", \"Doctorate\", \"5th-6th\", \"Preschool\"],\n",
        "                                       label=\"Education\", value=\"Bachelors\")\n",
        "                marital_status = gr.Dropdown(choices=[\"Married-civ-spouse\", \"Divorced\", \"Never-married\",\n",
        "                                                     \"Separated\", \"Widowed\", \"Married-spouse-absent\",\n",
        "                                                     \"Married-AF-spouse\"],\n",
        "                                            label=\"Marital Status\", value=\"Never-married\")\n",
        "                occupation = gr.Dropdown(choices=[\"Tech-support\", \"Craft-repair\", \"Other-service\", \"Sales\",\n",
        "                                                 \"Exec-managerial\", \"Prof-specialty\", \"Handlers-cleaners\",\n",
        "                                                 \"Machine-op-inspct\", \"Adm-clerical\", \"Farming-fishing\",\n",
        "                                                 \"Transport-moving\", \"Priv-house-serv\", \"Protective-serv\",\n",
        "                                                 \"Armed-Forces\"],\n",
        "                                        label=\"Occupation\", value=\"Adm-clerical\")\n",
        "                relationship = gr.Dropdown(choices=[\"Wife\", \"Own-child\", \"Husband\", \"Not-in-family\",\n",
        "                                                   \"Other-relative\", \"Unmarried\"],\n",
        "                                          label=\"Relationship\", value=\"Not-in-family\")\n",
        "                race = gr.Dropdown(choices=[\"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\"],\n",
        "                                  label=\"Race\", value=\"White\")\n",
        "                sex = gr.Dropdown(choices=[\"Male\", \"Female\"], label=\"Sex\", value=\"Male\")\n",
        "                native_country = gr.Dropdown(choices=[\"United-States\", \"Cambodia\", \"England\", \"Puerto-Rico\",\n",
        "                                                     \"Canada\", \"Germany\", \"Outlying-US(Guam-USVI-etc)\", \"India\",\n",
        "                                                     \"Japan\", \"Greece\", \"South\", \"China\", \"Cuba\", \"Iran\", \"Honduras\",\n",
        "                                                     \"Philippines\", \"Italy\", \"Poland\", \"Jamaica\", \"Vietnam\", \"Mexico\",\n",
        "                                                     \"Portugal\", \"Ireland\", \"France\", \"Dominican-Republic\", \"Laos\",\n",
        "                                                     \"Ecuador\", \"Taiwan\", \"Haiti\", \"Columbia\", \"Hungary\", \"Guatemala\",\n",
        "                                                     \"Nicaragua\", \"Scotland\", \"Thailand\", \"Yugoslavia\", \"El-Salvador\",\n",
        "                                                     \"Trinadad&Tobago\", \"Peru\", \"Hong\", \"Holand-Netherlands\"],\n",
        "                                            label=\"Native Country\", value=\"United-States\")\n",
        "\n",
        "                predict_btn = gr.Button(\"Predict Your Income\")\n",
        "                train_btn = gr.Button(\"Train Model\")\n",
        "\n",
        "            with gr.Column(scale=3):\n",
        "                output_text = gr.Textbox(label=\"Training Results\", lines=15)\n",
        "                output_plot = gr.Image(label=\"Training Plots\")\n",
        "                prediction_output = gr.Textbox(label=\"Your Income Prediction\")\n",
        "\n",
        "        train_btn.click(fn=train_model, inputs=[model_dropdown, tune_checkbox],\n",
        "                        outputs=[output_text, output_plot])\n",
        "        predict_btn.click(fn=predict_user_input,\n",
        "                         inputs=[model_dropdown, age, fnlwgt, education_num, capital_gain, capital_loss,\n",
        "                                hours_per_week, workclass, education, marital_status, occupation,\n",
        "                                relationship, race, sex, native_country],\n",
        "                         outputs=prediction_output)\n",
        "    return demo\n",
        "\n",
        "# Main execution\n",
        "demo = create_gradio_interface()\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToAT78CJ1zrS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}